{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções com Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pessoa:\n",
    "    def __init__(self, nome: str, idade: int, peso: float) -> None:\n",
    "        self.nome = nome\n",
    "        self.idade = idade\n",
    "        self.peso = peso\n",
    "\n",
    "\n",
    "adriano = Pessoa(\"Adriano\", 30, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "30\n",
      "Adriano\n"
     ]
    }
   ],
   "source": [
    "print(adriano.peso)\n",
    "print(adriano.idade)\n",
    "print(adriano.nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções com Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydPessoa(nome='Adriano', idade=30, peso=80.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class pydPessoa(BaseModel):\n",
    "    nome: str\n",
    "    idade: int\n",
    "    peso: float\n",
    "\n",
    "adriano = pydPessoa(nome=\"Adriano\", idade=30, peso=80)\n",
    "adriano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydAsimovTeam(funcionarios=[pydPessoa(nome='Rafael', idade=30, peso=68.0)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "class pydAsimovTeam(BaseModel):\n",
    "    funcionarios : List[pydPessoa]\n",
    "\n",
    "pydAsimovTeam(funcionarios = [pydPessoa(nome='Rafael', idade=30, peso=68)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def obter_temperatura_atual(local, unidade=\"celsius\"):\n",
    "    if \"sao paulo\" in local.lower():\n",
    "        return json.dumps({\n",
    "            \"local\": \"Sao Paulo\", \n",
    "            \"temperatura\": 32, \n",
    "            \"unidade\": unidade})\n",
    "    elif \"porto alegre\" in local.lower():\n",
    "        return json.dumps({\n",
    "            \"local\": \"Porto Alegre\",\n",
    "            \"temperatura\": 25,\n",
    "            \"unidade\": unidade})\n",
    "    else:\n",
    "        return json.dumps({\n",
    "            \"local\": local,\n",
    "            \"temperatura\": \"unknown\",\n",
    "})\n",
    "    \n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"obter_temperatura_atual\",\n",
    "        \"description\": \"Obtem temperatura atual da cidade\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"local\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"O nome da cidade. Exemplo: São Paulo\",\n",
    "                },\n",
    "                \"unidade\": {\n",
    "                    \"type\": \"string\", \n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"local\"]\n",
    "        },\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\OneDrive\\Documentos\\Projetos\\Regdoor\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "\n",
    "class UnidadeEnum(str, Enum):\n",
    "    celsius = \"celsius\"\n",
    "    fahrenheit = \"fahrenheit\"\n",
    "\n",
    "class ObterTemperaturaAtual(BaseModel):\n",
    "    \"\"\"Obtem a temperatura atual de uma determinada localidade\"\"\"\n",
    "    local: str = Field(description=\"O nome da cidade.\", examples=[\"São Paulo\", \"Porto Alegre\"])\n",
    "    unidade: Optional[UnidadeEnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ObterTemperaturaAtual',\n",
       " 'description': 'Obtem a temperatura atual de uma determinada localidade',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'local': {'description': 'O nome da cidade.',\n",
       "    'examples': ['São Paulo', 'Porto Alegre'],\n",
       "    'type': 'string'},\n",
       "   'unidade': {'description': 'An enumeration.',\n",
       "    'enum': ['celsius', 'fahrenheit'],\n",
       "    'type': 'string'}},\n",
       "  'required': ['local']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tool_temperatura = convert_to_openai_function(ObterTemperaturaAtual)\n",
    "tool_temperatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando a funçao a Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'arguments': '{\"local\":\"Porto Alegre\",\"unidade\":\"celsius\"}', 'name': 'ObterTemperaturaAtual'}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 105, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None} id='run-c69ab0e8-8b13-43cf-a6cb-c261f4e2f12a-0' usage_metadata={'input_tokens': 105, 'output_tokens': 30, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "resposta = chat.invoke(\"Qual a temperatura atual em Porto Alegre\", functions=[tool_temperatura])\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplificando o processo adicionando a função a reiz do nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'arguments': '{\"local\":\"São Paulo\"}', 'name': 'ObterTemperaturaAtual'}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 103, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None} id='run-ea0c774e-482a-456d-b8d9-7140858054aa-0' usage_metadata={'input_tokens': 103, 'output_tokens': 22, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chat_function = chat.bind(functions=[tool_temperatura])\n",
    "resposta = chat_function.invoke(\"Qual a temperatura em São Paulo?\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obrigando o modelo a usar a função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Porto Alegre\"}', 'name': 'ObterTemperaturaAtual'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 119, 'total_tokens': 129, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1e3f240e-9b3f-4af3-acd9-5c6fc5e640f9-0', usage_metadata={'input_tokens': 119, 'output_tokens': 10, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = chat.invoke(\n",
    "    \"Qual a temperatura atual em Porto Alegre\", \n",
    "    functions=[tool_temperatura],\n",
    "    function_call= {\"name\": \"ObterTemperaturaAtual\"}\n",
    ")\n",
    "resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando a uma Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Florianópolis\"}', 'name': 'ObterTemperaturaAtual'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 118, 'total_tokens': 142, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-6631505e-3dc5-4d57-859a-d0abd577d2c3-0', usage_metadata={'input_tokens': 118, 'output_tokens': 24, 'total_tokens': 142, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente grosso e arrogante chamado Isacc\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat.bind(functions=[tool_temperatura])\n",
    "\n",
    "chain.invoke({\"input\": \"Qual a temperatura em Floripa?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
