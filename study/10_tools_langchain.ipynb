{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArXiv\n",
    "Biblioteca para obter resumos de artigos cientificos de um determinado tema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando tool manualmente através dp Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\OneDrive\\Documentos\\Projetos\\GitHub\\Regdoor_Project\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "class ArxivArgs(BaseModel):\n",
    "    query: str = Field(\n",
    "        description=\"Query para buscar no Arxiv\",\n",
    "    )\n",
    "\n",
    "tool_arxiv = StructuredTool.from_function(\n",
    "    func=ArxivAPIWrapper(top_k_results=2).run,\n",
    "    name=\"Arxiv\",\n",
    "    args_schema=ArxivArgs,\n",
    "    return_direct=True,\n",
    "    description=(\n",
    "        \"Uma ferramenta em torno do Arxiv.org. \"\n",
    "        \"Útil para quando você precisa responder a perguntas sobre Física, Matemática, \"\n",
    "        \"Ciência da Computação, Biologia Quantitativa, Finanças Quantitativas, Estatística, \"\n",
    "        \"Engenharia Elétrica e Economia \"\n",
    "        \"utilizando artigos científicos do arxiv.org. \"\n",
    "        \"A entrada deve ser uma consulta de pesquisa em inglês.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição:  Uma ferramenta em torno do Arxiv.org. Útil para quando você precisa responder a perguntas sobre Física, Matemática, Ciência da Computação, Biologia Quantitativa, Finanças Quantitativas, Estatística, Engenharia Elétrica e Economia utilizando artigos científicos do arxiv.org. A entrada deve ser uma consulta de pesquisa em inglês.\n",
      "Args:  {'query': {'title': 'Query', 'description': 'Query para buscar no Arxiv', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Descrição: \", tool_arxiv.description)\n",
    "print(\"Args: \", tool_arxiv.args_schema.schema()[\"properties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-12-23\\nTitle: Trustworthy and Efficient LLMs Meet Databases\\nAuthors: Kyoungmin Kim, Anastasia Ailamaki\\nSummary: In the rapidly evolving AI era with large language models (LLMs) at the core,\\nmaking LLMs more trustworthy and efficient, especially in output generation\\n(inference), has gained significant attention. This is to reduce plausible but\\nfaulty LLM outputs (a.k.a hallucinations) and meet the highly increased\\ninference demands. This tutorial explores such efforts and makes them\\ntransparent to the database community. Understanding these efforts is essential\\nin harnessing LLMs in database tasks and adapting database techniques to LLMs.\\nFurthermore, we delve into the synergy between LLMs and databases, highlighting\\nnew opportunities and challenges in their intersection. This tutorial aims to\\nshare with database researchers and practitioners essential concepts and\\nstrategies around LLMs, reduce the unfamiliarity of LLMs, and inspire joining\\nin the intersection between LLMs and databases.\\n\\nPublished: 2024-06-13\\nTitle: Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications\\nAuthors: Irene Weber\\nSummary: Large Language Models (LLMs) have become widely adopted recently. Research\\nexplores their use both as autonomous agents and as tools for software\\nengineering. LLM-integrated applications, on the other hand, are software\\nsystems that leverage an LLM to perform tasks that would otherwise be\\nimpossible or require significant coding effort. While LLM-integrated\\napplication engineering is emerging as new discipline, its terminology,\\nconcepts and methods need to be established. This study provides a taxonomy for\\nLLM-integrated applications, offering a framework for analyzing and describing\\nthese systems. It also demonstrates various ways to utilize LLMs in\\napplications, as well as options for implementing such integrations.\\n  Following established methods, we analyze a sample of recent LLM-integrated\\napplications to identify relevant dimensions. We evaluate the taxonomy by\\napplying it to additional cases. This review shows that applications integrate\\nLLMs in numerous ways for various purposes. Frequently, they comprise multiple\\nLLM integrations, which we term ``LLM components''. To gain a clear\\nunderstanding of an application's architecture, we examine each LLM component\\nseparately. We identify thirteen dimensions along which to characterize an LLM\\ncomponent, including the LLM skills leveraged, the format of the output, and\\nmore. LLM-integrated applications are described as combinations of their LLM\\ncomponents. We suggest a concise representation using feature vectors for\\nvisualization.\\n  The taxonomy is effective for describing LLM-integrated applications. It can\\ncontribute to theory building in the nascent field of LLM-integrated\\napplication engineering and aid in developing such systems. Researchers and\\npractitioners explore numerous creative ways to leverage LLMs in applications.\\nThough challenges persist, integrating LLMs may revolutionize the way software\\nsystems are built.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arxiv.run({\"query\":\"llm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciando tool já criada no Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "tool_arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição:  A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\n",
      "Args:  {'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_1468\\2394365036.py:2: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(\"Args: \", tool_arxiv.args_schema.schema()[\"properties\"])\n"
     ]
    }
   ],
   "source": [
    "print(\"Descrição: \", tool_arxiv.description)\n",
    "print(\"Args: \", tool_arxiv.args_schema.schema()[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando tool através de load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools([\"arxiv\"])\n",
    "tool_arxiv = tools[0]\n",
    "tool_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição:  A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\n",
      "Args:  {'query': {'description': 'search query to look up', 'title': 'Query', 'type': 'string'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_1468\\2394365036.py:2: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(\"Args: \", tool_arxiv.args_schema.schema()[\"properties\"])\n"
     ]
    }
   ],
   "source": [
    "print(\"Descrição: \", tool_arxiv.description)\n",
    "print(\"Args: \", tool_arxiv.args_schema.schema()[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
      "Argumentos: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "tool_repl = PythonREPLTool()\n",
    "print(\"Descrição:\", tool_repl.description)\n",
    "print(\"Argumentos:\", tool_repl.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'oi\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_repl.run({\"query\":\"print('oi')\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A wrapper around StackExchange. Useful for when you need to answer specific programming questionscode excerpts, code examples and solutionsInput should be a fully formed question.\n",
      "Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools([\"stackexchange\"])\n",
    "tools_stack = tools[0]\n",
    "print(\"Descrição:\",tools_stack.description)\n",
    "print(\"Args:\", tools_stack.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Seeking solutions for agentic llm solution using langchain and gpt4o-mini\\nDear Stackoverflow Community,\\nTo streamline create and update operations, we are working on built an agentic solution that automates API calls. A key challenge was reliably gathering all the necessary &hellip; \\n\\nQuestion: LangChainDeprecationWarning:\\nI&#39;ve created an <span class=\"highlight\">langchain</span> based <span class=\"highlight\">agent</span> where I use chain and invoke it. I got this this warning while running it. &hellip; LangChainDeprecationWarning: The class LLMChain was deprecated in <span class=\"highlight\">LangChain</span> 0.1.17 and will be removed in 1.0. &hellip; \\n\\nQuestion: My Langchain text2SQL agent is stuck in an infinite results loop\\nI am trying tobuild a text to SQL <span class=\"highlight\">Agent</span> using Ollama and Llama 3.1, connected to a SQLite database. &hellip; But when I execute the code, It seems the execute_query node does not receive the generated SQL query, and it makes the <span class=\"highlight\">agent</span> run into an endless loop until it hits a timeout. &hellip; '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_stack.run({\"query\": \"langchain agents\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System\n",
    "Faz manipulação de arquivos utilizando LLMs (deletar, mover, deletar arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_file\n",
      "Create a copy of a file in a specified location\n",
      "{'description': 'Input for CopyFileTool.', 'properties': {'source_path': {'description': 'Path of the file to copy', 'title': 'Source Path', 'type': 'string'}, 'destination_path': {'description': 'Path to save the copied file', 'title': 'Destination Path', 'type': 'string'}}, 'required': ['source_path', 'destination_path'], 'title': 'FileCopyInput', 'type': 'object'}\n",
      "\n",
      "\n",
      "file_delete\n",
      "Delete a file\n",
      "{'description': 'Input for DeleteFileTool.', 'properties': {'file_path': {'description': 'Path of the file to delete', 'title': 'File Path', 'type': 'string'}}, 'required': ['file_path'], 'title': 'FileDeleteInput', 'type': 'object'}\n",
      "\n",
      "\n",
      "file_search\n",
      "Recursively search for files in a subdirectory that match the regex pattern\n",
      "{'description': 'Input for FileSearchTool.', 'properties': {'dir_path': {'default': '.', 'description': 'Subdirectory to search in.', 'title': 'Dir Path', 'type': 'string'}, 'pattern': {'description': 'Unix shell regex, where * matches everything.', 'title': 'Pattern', 'type': 'string'}}, 'required': ['pattern'], 'title': 'FileSearchInput', 'type': 'object'}\n",
      "\n",
      "\n",
      "move_file\n",
      "Move or rename a file from one location to another\n",
      "{'description': 'Input for MoveFileTool.', 'properties': {'source_path': {'description': 'Path of the file to move', 'title': 'Source Path', 'type': 'string'}, 'destination_path': {'description': 'New path for the moved file', 'title': 'Destination Path', 'type': 'string'}}, 'required': ['source_path', 'destination_path'], 'title': 'FileMoveInput', 'type': 'object'}\n",
      "\n",
      "\n",
      "read_file\n",
      "Read file from disk\n",
      "{'description': 'Input for ReadFileTool.', 'properties': {'file_path': {'description': 'name of file', 'title': 'File Path', 'type': 'string'}}, 'required': ['file_path'], 'title': 'ReadFileInput', 'type': 'object'}\n",
      "\n",
      "\n",
      "write_file\n",
      "Write file to disk\n",
      "{'description': 'Input for WriteFileTool.', 'properties': {'file_path': {'description': 'name of file', 'title': 'File Path', 'type': 'string'}, 'text': {'description': 'text to write to file', 'title': 'Text', 'type': 'string'}, 'append': {'default': False, 'description': 'Whether to append to an existing file.', 'title': 'Append', 'type': 'boolean'}}, 'required': ['file_path', 'text'], 'title': 'WriteFileInput', 'type': 'object'}\n",
      "\n",
      "\n",
      "list_directory\n",
      "List files and directories in a specified folder\n",
      "{'description': 'Input for ListDirectoryTool.', 'properties': {'dir_path': {'default': '.', 'description': 'Subdirectory to list.', 'title': 'Dir Path', 'type': 'string'}}, 'title': 'DirectoryListingInput', 'type': 'object'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_1468\\1196455.py:11: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(tool.args_schema.schema())\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "    root_dir=\"study\"\n",
    ")\n",
    "\n",
    "tools = tool_kit.get_tools()\n",
    "for tool in tools:\n",
    "    print(tool.name)\n",
    "    print(tool.description)\n",
    "    print(tool.args_schema.schema())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m tools \u001b[38;5;241m=\u001b[39m tool_kit\u001b[38;5;241m.\u001b[39mget_tools()\n\u001b[0;32m     11\u001b[0m tools_json \u001b[38;5;241m=\u001b[39m [convert_to_openai_function(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools]\n\u001b[1;32m---> 12\u001b[0m tool_run \u001b[38;5;241m=\u001b[39m {tool: tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools_json}  \u001b[38;5;66;03m# Corrigido para acessar o nome corretamente\u001b[39;00m\n\u001b[0;32m     14\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     15\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoce é um assistente que é capaz de gerenciar arquivos\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m ])\n\u001b[0;32m     19\u001b[0m tool_run\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "    root_dir=\"study\",\n",
    "    selected_tools=[\"read_file\", \"write_file\", \"list_directory\", \"file_delete\", \"file_search\"]\n",
    ")\n",
    "tools = tool_kit.get_tools()\n",
    "\n",
    "tools_json = [convert_to_openai_function(tool) for tool in tools]\n",
    "tool_run = {tool: tool for tool in tools_json}  # Corrigido para acessar o nome corretamente\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Voce é um assistente que é capaz de gerenciar arquivos\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "tool_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Desculpe, não entendi sua pergunta. Você gostaria de saber quais arquivos estão presentes em um diretório específico?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.agent import AgentFinish\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "def roteamento(resultado):\n",
    "    if isinstance(resultado, AgentFinish):\n",
    "        return resultado.return_values[\"output\"]\n",
    "    else:\n",
    "        return tool_run[resultado.tool].run(resultado.tool_input)\n",
    "    \n",
    "chat = ChatOpenAI()\n",
    "chain = prompt | chat.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser() | roteamento\n",
    "\n",
    "chain.invoke({\"input\": \"que arquivos vc\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
