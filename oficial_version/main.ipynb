{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regdoor Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar o feito até o momento, precisaremos de uma classe pydantic para extrair as informações, precisaremos da tool/função \"ExtraiInformacoes\" para que seja acionada quando o agente tiver todos os dados necessarios, e uma outra tool/função sera criada para enviar estes dados para o banco de dados, da mesma forma que uma também deverá ser criada para fazer o get das informações no database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a extrutura do agente com agent executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema.agent import AgentFinish\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import Tool\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_14956\\4146248363.py:56: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m\n\u001b[0;32m     61\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     62\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocê é um assistente juridico que extrai informações do texto fornecido. Para referencia a data atual é \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_atual\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     63\u001b[0m     MessagesPlaceholder(variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     64\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     65\u001b[0m     MessagesPlaceholder(variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m ])\n\u001b[0;32m     68\u001b[0m pass_through \u001b[38;5;241m=\u001b[39m RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m     69\u001b[0m     agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_function_messages(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     70\u001b[0m )\n\u001b[1;32m---> 71\u001b[0m agent_chain \u001b[38;5;241m=\u001b[39m pass_through \u001b[38;5;241m|\u001b[39m prompt \u001b[38;5;241m|\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mbind(functions\u001b[38;5;241m=\u001b[39mtoolls_json) \u001b[38;5;241m|\u001b[39m OpenAIFunctionsAgentOutputParser()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_agent\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m     75\u001b[0m     passos_intermediarios \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chat' is not defined"
     ]
    }
   ],
   "source": [
    "def obter_hora_e_data_atual():\n",
    "    \"\"\"Retorna a hora atual e a data de hoje.\"\"\"\n",
    "    agora = datetime.now()\n",
    "    return agora.strftime(\"%d-%m-%Y - %H:%M:%S\")\n",
    "\n",
    "\n",
    "data_atual = obter_hora_e_data_atual()\n",
    "texto = \"\"\"Olá, tive uma reunião mais cedo hoje com representantes tanto da Autoridade Europeia dos Valores Mobiliários e dos \n",
    "Mercados (ESMA) quanto da Autoridade de Supervisão Financeira da Suécia (FSA). Discutimos a harmonização das \n",
    "regulamentações de ativos digitais em jurisdições da UE e os desafios específicos na implementação de estruturas de \n",
    "conformidade.\"\"\"\n",
    "\n",
    "\n",
    "class ExtraiInformacoes(BaseModel):\n",
    "    \"\"\"Extrair informações dos textos fornecidos\"\"\"\n",
    "    data: str = Field (description=\"data em que o o evento ocorreu\")\n",
    "    contatos : str = Field(\n",
    "        description=\"nome das pessoas contidas no texto\", \n",
    "        examples=[\n",
    "            (\"Me chamo Rafael e falei com o Junior sobre assunto XYZ.\", \"Rafael, Junior\"), \n",
    "            (\"Me chamo Alfredo e falei com o Severino sobre assunto a posse dos Eua.\", \"Alfredo, Severino\")\n",
    "        ])\n",
    "    cargo: str = Field(description=\"cargo dos contatos mencionados\")\n",
    "    organizacoes : str = Field(description=\"organizaçao dos contatos mencionados\")\n",
    "    jurisdicoes : str = Field(\n",
    "        description=\"jurisdições mencionadas\",\n",
    "        examples=[\n",
    "            (\"Jane Doe is a Senior Regulatory Advisor at the Financial Conduct Authority (FCA) in the UK. I don't have her email or phone number at the moment. \", \"UK\")\n",
    "        ])\n",
    "    representantes : str = Field(description=\"representantes dos contatos mencionados\")\n",
    "    assunto : str = Field(description=\"assunto do texto, deve ser 'politica', 'economia' ou 'justica'.\")\n",
    "    resumo : str = Field(description=\"resumo do texto, deve ser uma breve descrição do evento, com no máximo 100 caracteres.\")\n",
    "    acoes_acompanhamento : str = Field(description=\"acoes de acompanhamento do texto.\")\n",
    "    sentimento : str = Field(description=\"sentimento expresso pelo individuo, deve ser 'positivo', 'negativo' ou 'neutro'.\")\n",
    "\n",
    "\n",
    "@tool(args_schema=ExtraiInformacoes)\n",
    "def extrutura_informacao(\n",
    "        data: str, \n",
    "        contatos : str, \n",
    "        cargo: str, \n",
    "        organizacoes: str, \n",
    "        jurisdicoes: str, \n",
    "        representantes: str, \n",
    "        assunto: str, \n",
    "        resumo: str, \n",
    "        acoes_acompanhamento: str, \n",
    "        sentimento: str ):\n",
    "    \n",
    "    \"\"\"Extrutura as informações do texto\"\"\"\n",
    "    return data, contatos, cargo, organizacoes, jurisdicoes, representantes, assunto, resumo, acoes_acompanhamento, sentimento\n",
    "\n",
    "toolls = [extrutura_informacao]\n",
    "toolls_json = [convert_to_openai_function(tooll) for tooll in toolls]\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"Você é um assistente juridico que extrai informações do texto fornecido. Para referencia a data atual é {data_atual}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "pass_through = RunnablePassthrough.assign(\n",
    "    agent_scratchpad=lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
    ")\n",
    "agent_chain = pass_through | prompt | chat.bind(functions=toolls_json) | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "\n",
    "def run_agent(input):\n",
    "    passos_intermediarios = []\n",
    "    while True:\n",
    "        resposta = agent_chain.invoke({\n",
    "            \"input\": input,\n",
    "            \"agent_scratchpad\": format_to_openai_function_messages(passos_intermediarios)\n",
    "        })\n",
    "        if isinstance(resposta, AgentFinish):\n",
    "            return resposta\n",
    "        observacao = toolls[resposta.tool].run(resposta.tool_input)\n",
    "        passos_intermediarios.append((resposta, observacao))\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent_chain,\n",
    "    memory=memory,\n",
    "    tools=toolls,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSua última pergunta foi: \"Qual minha ultima prgunta??\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Qual minha ultima prgunta??',\n",
       " 'chat_history': [HumanMessage(content='Quem são os representantes?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Os representantes mencionados no texto não foram fornecidos. Para que eu possa ajudar, por favor, forneça o texto com as informações necessárias.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Qual minha ultima prgunta??', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Sua última pergunta foi: \"Quem são os representantes?\"', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Qual minha ultima prgunta??', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Sua última pergunta foi: \"Qual minha ultima prgunta??\"', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Qual minha ultima prgunta??', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Sua última pergunta foi: \"Qual minha ultima prgunta??\"', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Sua última pergunta foi: \"Qual minha ultima prgunta??\"'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = agent_executor.invoke({\"input\": \"Qual minha ultima prgunta??\"})\n",
    "resposta\n",
    "#resposta[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=api_key)\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Hello, AI!\n",
      "ai: Hello, human! How can I assist you today?\n",
      "bar\n"
     ]
    }
   ],
   "source": [
    "#langchain redis connection\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "history = RedisChatMessageHistory(\n",
    "    session_id=\"default\",\n",
    "    redis_url=\"redis://default:A1ZDEbkF87w7TR0MPTBREnTFOnBgfBw9@redis-14693.c253.us-central1-1.gce.redns.redis-cloud.com:14693/0\"\n",
    ")\n",
    "\n",
    "# Adiciona mensagens ao histórico\n",
    "history.add_message(HumanMessage(content=\"Hello, AI!\"))\n",
    "history.add_message(AIMessage(content=\"Hello, human! How can I assist you today?\"))\n",
    "\n",
    "# Recupera todas as mensagens\n",
    "messages = history.messages\n",
    "for message in messages:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n",
    "\n",
    "#redis conection\n",
    "import redis\n",
    "\n",
    "r = redis.Redis(\n",
    "    host='redis-14693.c253.us-central1-1.gce.redns.redis-cloud.com',\n",
    "    port=14693,\n",
    "    decode_responses=True,\n",
    "    username=\"default\",\n",
    "    password=\"A1ZDEbkF87w7TR0MPTBREnTFOnBgfBw9\",\n",
    ")\n",
    "\n",
    "success = r.set('foo', 'bar')\n",
    "# True\n",
    "\n",
    "result = r.get('foo')\n",
    "print(result)\n",
    "# >>> bar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
